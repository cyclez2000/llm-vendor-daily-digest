# Daily Digest / 日报摘要 (2026-02-23)

## English

### Anthropic
Anthropic details methods to detect and prevent distillation attacks on its AI models. | https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks

### OpenAI
OpenAI introduces the Frontier Alliance Partners program to help enterprises scale secure AI agents. | https://openai.com/index/frontier-alliance-partners

### OpenAI
OpenAI stops using SWE-bench Verified due to test contamination and training leakage, recommending SWE-bench Pro instead. | https://openai.com/index/why-we-no-longer-evaluate-swe-bench-verified

### Together AI
Together AI research reveals that state-of-the-art speech models fail 39% of the time on street names despite high benchmark scores. | https://www.together.ai/blog/how-speech-models-fail

## 中文

### Anthropic
Anthropic 介绍了检测和防止蒸馏攻击的方法。 | https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks

### OpenAI
OpenAI 宣布推出 Frontier Alliance Partners，帮助企业从 AI 原型转向安全、可扩展的代理部署。 | https://openai.com/index/frontier-alliance-partners

### OpenAI
OpenAI 停止评估 SWE-bench Verified，指出该数据集存在测试污染和训练泄露问题，无法准确衡量代码进展，并推荐使用 SWE-bench Pro。 | https://openai.com/index/why-we-no-longer-evaluate-swe-bench-verified

### Together AI
Together AI 的新研究显示，尽管 Whisper 和 Deepgram 等顶尖语音模型在基准测试中得分接近人类，但在路名识别上仍有 39% 的失败率。 | https://www.together.ai/blog/how-speech-models-fail
